{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-09 20:51:05--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: ‘./data/aclImdb_v1.tar.gz’\n",
      "\n",
      "./data/aclImdb_v1.t 100%[===================>]  80.23M   203KB/s    in 2m 35s  \n",
      "\n",
      "2020-03-09 20:53:41 (531 KB/s) - ‘./data/aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%mkdir ./data\n",
    "!wget -O ./data/aclImdb_v1.tar.gz http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -zxf ./data/aclImdb_v1.tar.gz -C ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB reviews: train = 12500 pos / 12500 neg, test = 12500 pos / 12500 neg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def read_imdb_data(data_dir='./data/aclImdb'):\n",
    "    data = {}\n",
    "    labels = {}\n",
    "    \n",
    "    for data_type in ['train', 'test']:\n",
    "        data[data_type] = {}\n",
    "        labels[data_type] = {}\n",
    "        \n",
    "        for sentiment in ['pos', 'neg']:\n",
    "            data[data_type][sentiment] = []\n",
    "            labels[data_type][sentiment] = []\n",
    "            \n",
    "            path = os.path.join(data_dir, data_type, sentiment, '*.txt')\n",
    "            files = glob.glob(path)\n",
    "            \n",
    "            for f in files:\n",
    "                with open(f) as review:\n",
    "                    data[data_type][sentiment].append(review.read())\n",
    "                    # Here we represent a positive review by '1' and a negative review by '0'\n",
    "                    labels[data_type][sentiment].append(1 if sentiment == 'pos' else 0)\n",
    "                    \n",
    "            assert len(data[data_type][sentiment]) == len(labels[data_type][sentiment]), \\\n",
    "                    \"{}/{} data size does not match labels size\".format(data_type, sentiment)\n",
    "                \n",
    "    return data, labels\n",
    "\n",
    "data, labels = read_imdb_data()\n",
    "print(\"IMDB reviews: train = {} pos / {} neg, test = {} pos / {} neg\".format(\n",
    "            len(data['train']['pos']), len(data['train']['neg']),\n",
    "            len(data['test']['pos']), len(data['test']['neg'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDb reviews (combined): train = 25000, test = 25000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def prepare_imdb_data(data, labels):\n",
    "    \"\"\"Prepare training and test sets from IMDb movie reviews.\"\"\"\n",
    "    \n",
    "    #Combine positive and negative reviews and labels\n",
    "    data_train = data['train']['pos'] + data['train']['neg']\n",
    "    data_test = data['test']['pos'] + data['test']['neg']\n",
    "    labels_train = labels['train']['pos'] + labels['train']['neg']\n",
    "    labels_test = labels['test']['pos'] + labels['test']['neg']\n",
    "    \n",
    "    #Shuffle reviews and corresponding labels within training and test sets\n",
    "    data_train, labels_train = shuffle(data_train, labels_train)\n",
    "    data_test, labels_test = shuffle(data_test, labels_test)\n",
    "    \n",
    "    # Return a unified training data, test data, training labels, test labets\n",
    "    return data_train, data_test, labels_train, labels_test\n",
    "\n",
    "train_X, test_X, train_y, test_y = prepare_imdb_data(data, labels)\n",
    "print(\"IMDb reviews (combined): train = {}, test = {}\".format(len(train_X), len(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7d12772149b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "print(train_X[100])\n",
    "print(train_y[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plot', 'real', 'horrif', 'atmospher', 'realli', 'depress', 'unusu', 'low', 'budget', 'product', 'like', 'least', 'german', 'product', 'littl', 'bit', 'indian', 'spiritu', 'mystic', 'thriller', 'slasher', 'movi', 'mix', 'togeth', 'develop', 'plot', 'charact', 'great', 'set', 'close', 'realiti', 'without', 'studio', 'atmospher', 'could', 'perfect', 'unfortun', 'thing', 'littl', 'bit', 'disappoint', 'inevit', 'typic', 'low', 'budget', 'movi', '1', 'cast', 'sometim', 'averag', 'almost', 'everi', 'actor', 'look', 'like', 'layman', 'good', 'good', 'job', 'act', 'like', 'actor', 'crappi', 'german', 'court', 'show', 'disappoint', 'act', 'mathieu', 'carri', 'act', 'lot', 'older', 'movi', 'act', 'fine', 'averag', 'could', 'reason', 'today', 'take', 'part', 'crappi', 'german', 'soap', 'tv', 'seri', 'privat', 'channel', '2', 'dialog', 'sometim', 'soap', 'opera', 'level', '3', 'bad', 'sound', 'made', 'sometim', 'hard', 'understand', 'charact', 'say', 'saw', 'dvd', 'glad', 'could', 'rewind', 'listen', 'caus', 'set', 'big', 'hall', 'hospit', 'esoter', 'group', 'sometim', 'strang', 'dialect', 'actor', 'interest', 'movi', 'worth', 'watch', 'far', 'beyond', 'commerci', 'movi', 'often', 'terribl']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def review_to_words(review):\n",
    "    nltk.download(\"stopwords\", quiet=True)\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    text = BeautifulSoup(review, \"html.parser\").get_text() # Remove HTML tags\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) # Convert to lower case\n",
    "    words = text.split() # Split string into words\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n",
    "    words = [PorterStemmer().stem(w) for w in words] # stem\n",
    "    \n",
    "    return words\n",
    "\n",
    "print(review_to_words(train_X[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "cache_dir = os.path.join(\"../cache\", \"sentiment_analysis\")  # where to store cache files\n",
    "os.makedirs(cache_dir, exist_ok=True)  # ensure cache directory exists\n",
    "\n",
    "def preprocess_data(data_train=None, data_test=None, labels_train=None, labels_test=None,\n",
    "                    cache_dir=cache_dir, cache_file=\"preprocessed_data.pkl\"):\n",
    "    \"\"\"Convert each review to words; read from cache if available.\"\"\"\n",
    "\n",
    "    # If cache_file is not None, try to read from it first\n",
    "    cache_data = None\n",
    "    if cache_file is not None:\n",
    "        try:\n",
    "            with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n",
    "                cache_data = pickle.load(f)\n",
    "            print(\"Read preprocessed data from cache file:\", cache_file)\n",
    "        except:\n",
    "            pass  # unable to read from cache, but that's okay\n",
    "    \n",
    "    # If cache is missing, then do the heavy lifting\n",
    "    if cache_data is None:\n",
    "        # Preprocess training and test data to obtain words for each review\n",
    "        #words_train = list(map(review_to_words, data_train))\n",
    "        #words_test = list(map(review_to_words, data_test))\n",
    "        words_train = [review_to_words(review) for review in data_train]\n",
    "        words_test = [review_to_words(review) for review in data_test]\n",
    "        \n",
    "        # Write to cache file for future runs\n",
    "        if cache_file is not None:\n",
    "            cache_data = dict(words_train=words_train, words_test=words_test,\n",
    "                              labels_train=labels_train, labels_test=labels_test)\n",
    "            with open(os.path.join(cache_dir, cache_file), \"wb\") as f:\n",
    "                pickle.dump(cache_data, f)\n",
    "            print(\"Wrote preprocessed data to cache file:\", cache_file)\n",
    "    else:\n",
    "        # Unpack data loaded from cache file\n",
    "        words_train, words_test, labels_train, labels_test = (cache_data['words_train'],\n",
    "                cache_data['words_test'], cache_data['labels_train'], cache_data['labels_test'])\n",
    "    \n",
    "    return words_train, words_test, labels_train, labels_test\n",
    "# Preprocess data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read preprocessed data from cache file: preprocessed_data.pkl\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "def build_dict(data, vocab_size = 5000):\n",
    "    \"\"\"Construct and return a dictionary mapping each of the most frequently appearing words to a unique integer.\"\"\"\n",
    "    \n",
    "    # TODO: Determine how often each word appears in `data`. Note that `data` is a list of sentences and that a\n",
    "    #       sentence is a list of words.\n",
    "    list_of_words = itertools.chain.from_iterable(data)\n",
    "    word_count = Counter(list_of_words) # A dict storing the words that appear in the reviews along with how often they occur\n",
    "    \n",
    "    # TODO: Sort the words found in `data` so that sorted_words[0] is the most frequently appearing word and\n",
    "    #       sorted_words[-1] is the least frequently appearing word.\n",
    "    \n",
    "    sorted_words = list(dict(word_count.most_common(vocab_size)).keys())\n",
    "    \n",
    "    word_dict = {} # This is what we are building, a dictionary that translates words into integers\n",
    "    for idx, word in enumerate(sorted_words[:vocab_size - 2]): # The -2 is so that we save room for the 'no word'\n",
    "        word_dict[word] = idx + 2                              # 'infrequent' labels\n",
    "        \n",
    "    return word_dict\n",
    "\n",
    "word_dict = build_dict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movi': 2,\n",
       " 'film': 3,\n",
       " 'one': 4,\n",
       " 'like': 5,\n",
       " 'time': 6,\n",
       " 'good': 7,\n",
       " 'make': 8,\n",
       " 'charact': 9,\n",
       " 'get': 10,\n",
       " 'see': 11,\n",
       " 'watch': 12,\n",
       " 'stori': 13,\n",
       " 'even': 14,\n",
       " 'would': 15,\n",
       " 'realli': 16,\n",
       " 'well': 17,\n",
       " 'scene': 18,\n",
       " 'look': 19,\n",
       " 'show': 20,\n",
       " 'much': 21,\n",
       " 'end': 22,\n",
       " 'peopl': 23,\n",
       " 'bad': 24,\n",
       " 'go': 25,\n",
       " 'great': 26,\n",
       " 'also': 27,\n",
       " 'first': 28,\n",
       " 'love': 29,\n",
       " 'think': 30,\n",
       " 'way': 31,\n",
       " 'act': 32,\n",
       " 'play': 33,\n",
       " 'made': 34,\n",
       " 'thing': 35,\n",
       " 'could': 36,\n",
       " 'know': 37,\n",
       " 'say': 38,\n",
       " 'seem': 39,\n",
       " 'work': 40,\n",
       " 'plot': 41,\n",
       " 'two': 42,\n",
       " 'actor': 43,\n",
       " 'year': 44,\n",
       " 'come': 45,\n",
       " 'mani': 46,\n",
       " 'seen': 47,\n",
       " 'take': 48,\n",
       " 'want': 49,\n",
       " 'life': 50,\n",
       " 'never': 51,\n",
       " 'littl': 52,\n",
       " 'best': 53,\n",
       " 'tri': 54,\n",
       " 'man': 55,\n",
       " 'ever': 56,\n",
       " 'give': 57,\n",
       " 'better': 58,\n",
       " 'still': 59,\n",
       " 'perform': 60,\n",
       " 'find': 61,\n",
       " 'feel': 62,\n",
       " 'part': 63,\n",
       " 'back': 64,\n",
       " 'use': 65,\n",
       " 'someth': 66,\n",
       " 'director': 67,\n",
       " 'actual': 68,\n",
       " 'interest': 69,\n",
       " 'lot': 70,\n",
       " 'real': 71,\n",
       " 'old': 72,\n",
       " 'cast': 73,\n",
       " 'though': 74,\n",
       " 'live': 75,\n",
       " 'star': 76,\n",
       " 'enjoy': 77,\n",
       " 'guy': 78,\n",
       " 'anoth': 79,\n",
       " 'new': 80,\n",
       " 'role': 81,\n",
       " 'noth': 82,\n",
       " '10': 83,\n",
       " 'funni': 84,\n",
       " 'music': 85,\n",
       " 'point': 86,\n",
       " 'start': 87,\n",
       " 'set': 88,\n",
       " 'girl': 89,\n",
       " 'origin': 90,\n",
       " 'day': 91,\n",
       " 'world': 92,\n",
       " 'everi': 93,\n",
       " 'believ': 94,\n",
       " 'turn': 95,\n",
       " 'quit': 96,\n",
       " 'direct': 97,\n",
       " 'us': 98,\n",
       " 'thought': 99,\n",
       " 'fact': 100,\n",
       " 'minut': 101,\n",
       " 'horror': 102,\n",
       " 'kill': 103,\n",
       " 'action': 104,\n",
       " 'comedi': 105,\n",
       " 'pretti': 106,\n",
       " 'young': 107,\n",
       " 'wonder': 108,\n",
       " 'happen': 109,\n",
       " 'around': 110,\n",
       " 'got': 111,\n",
       " 'effect': 112,\n",
       " 'right': 113,\n",
       " 'long': 114,\n",
       " 'howev': 115,\n",
       " 'big': 116,\n",
       " 'line': 117,\n",
       " 'famili': 118,\n",
       " 'enough': 119,\n",
       " 'seri': 120,\n",
       " 'may': 121,\n",
       " 'need': 122,\n",
       " 'fan': 123,\n",
       " 'bit': 124,\n",
       " 'script': 125,\n",
       " 'beauti': 126,\n",
       " 'person': 127,\n",
       " 'becom': 128,\n",
       " 'without': 129,\n",
       " 'must': 130,\n",
       " 'alway': 131,\n",
       " 'friend': 132,\n",
       " 'tell': 133,\n",
       " 'reason': 134,\n",
       " 'saw': 135,\n",
       " 'last': 136,\n",
       " 'final': 137,\n",
       " 'kid': 138,\n",
       " 'almost': 139,\n",
       " 'put': 140,\n",
       " 'least': 141,\n",
       " 'sure': 142,\n",
       " 'done': 143,\n",
       " 'whole': 144,\n",
       " 'place': 145,\n",
       " 'complet': 146,\n",
       " 'kind': 147,\n",
       " 'expect': 148,\n",
       " 'differ': 149,\n",
       " 'shot': 150,\n",
       " 'far': 151,\n",
       " 'mean': 152,\n",
       " 'anyth': 153,\n",
       " 'book': 154,\n",
       " 'laugh': 155,\n",
       " 'might': 156,\n",
       " 'name': 157,\n",
       " 'sinc': 158,\n",
       " 'begin': 159,\n",
       " '2': 160,\n",
       " 'probabl': 161,\n",
       " 'woman': 162,\n",
       " 'help': 163,\n",
       " 'entertain': 164,\n",
       " 'let': 165,\n",
       " 'screen': 166,\n",
       " 'call': 167,\n",
       " 'tv': 168,\n",
       " 'moment': 169,\n",
       " 'away': 170,\n",
       " 'read': 171,\n",
       " 'yet': 172,\n",
       " 'rather': 173,\n",
       " 'worst': 174,\n",
       " 'run': 175,\n",
       " 'fun': 176,\n",
       " 'lead': 177,\n",
       " 'hard': 178,\n",
       " 'audienc': 179,\n",
       " 'idea': 180,\n",
       " 'anyon': 181,\n",
       " 'episod': 182,\n",
       " 'american': 183,\n",
       " 'found': 184,\n",
       " 'appear': 185,\n",
       " 'bore': 186,\n",
       " 'especi': 187,\n",
       " 'although': 188,\n",
       " 'hope': 189,\n",
       " 'cours': 190,\n",
       " 'keep': 191,\n",
       " 'anim': 192,\n",
       " 'job': 193,\n",
       " 'goe': 194,\n",
       " 'move': 195,\n",
       " 'sens': 196,\n",
       " 'dvd': 197,\n",
       " 'version': 198,\n",
       " 'war': 199,\n",
       " 'money': 200,\n",
       " 'someon': 201,\n",
       " 'mind': 202,\n",
       " 'mayb': 203,\n",
       " 'problem': 204,\n",
       " 'true': 205,\n",
       " 'hous': 206,\n",
       " 'everyth': 207,\n",
       " 'nice': 208,\n",
       " 'second': 209,\n",
       " 'rate': 210,\n",
       " 'three': 211,\n",
       " 'night': 212,\n",
       " 'face': 213,\n",
       " 'follow': 214,\n",
       " 'recommend': 215,\n",
       " 'product': 216,\n",
       " 'main': 217,\n",
       " 'worth': 218,\n",
       " 'leav': 219,\n",
       " 'human': 220,\n",
       " 'special': 221,\n",
       " 'excel': 222,\n",
       " 'togeth': 223,\n",
       " 'wast': 224,\n",
       " 'sound': 225,\n",
       " 'everyon': 226,\n",
       " 'john': 227,\n",
       " 'hand': 228,\n",
       " '1': 229,\n",
       " 'father': 230,\n",
       " 'later': 231,\n",
       " 'eye': 232,\n",
       " 'said': 233,\n",
       " 'view': 234,\n",
       " 'instead': 235,\n",
       " 'review': 236,\n",
       " 'boy': 237,\n",
       " 'high': 238,\n",
       " 'hour': 239,\n",
       " 'miss': 240,\n",
       " 'classic': 241,\n",
       " 'talk': 242,\n",
       " 'wife': 243,\n",
       " 'understand': 244,\n",
       " 'left': 245,\n",
       " 'care': 246,\n",
       " 'black': 247,\n",
       " 'death': 248,\n",
       " 'open': 249,\n",
       " 'murder': 250,\n",
       " 'write': 251,\n",
       " 'half': 252,\n",
       " 'head': 253,\n",
       " 'rememb': 254,\n",
       " 'chang': 255,\n",
       " 'viewer': 256,\n",
       " 'fight': 257,\n",
       " 'gener': 258,\n",
       " 'surpris': 259,\n",
       " 'short': 260,\n",
       " 'includ': 261,\n",
       " 'die': 262,\n",
       " 'fall': 263,\n",
       " 'less': 264,\n",
       " 'els': 265,\n",
       " 'entir': 266,\n",
       " 'piec': 267,\n",
       " 'involv': 268,\n",
       " 'pictur': 269,\n",
       " 'simpli': 270,\n",
       " 'top': 271,\n",
       " 'power': 272,\n",
       " 'home': 273,\n",
       " 'total': 274,\n",
       " 'usual': 275,\n",
       " 'budget': 276,\n",
       " 'attempt': 277,\n",
       " 'suppos': 278,\n",
       " 'releas': 279,\n",
       " 'hollywood': 280,\n",
       " 'terribl': 281,\n",
       " 'song': 282,\n",
       " 'men': 283,\n",
       " 'possibl': 284,\n",
       " 'featur': 285,\n",
       " 'portray': 286,\n",
       " 'disappoint': 287,\n",
       " '3': 288,\n",
       " 'poor': 289,\n",
       " 'coupl': 290,\n",
       " 'stupid': 291,\n",
       " 'camera': 292,\n",
       " 'dead': 293,\n",
       " 'wrong': 294,\n",
       " 'low': 295,\n",
       " 'produc': 296,\n",
       " 'either': 297,\n",
       " 'video': 298,\n",
       " 'aw': 299,\n",
       " 'definit': 300,\n",
       " 'except': 301,\n",
       " 'rest': 302,\n",
       " 'given': 303,\n",
       " 'absolut': 304,\n",
       " 'women': 305,\n",
       " 'lack': 306,\n",
       " 'word': 307,\n",
       " 'writer': 308,\n",
       " 'titl': 309,\n",
       " 'talent': 310,\n",
       " 'decid': 311,\n",
       " 'full': 312,\n",
       " 'perfect': 313,\n",
       " 'along': 314,\n",
       " 'style': 315,\n",
       " 'close': 316,\n",
       " 'truli': 317,\n",
       " 'school': 318,\n",
       " 'emot': 319,\n",
       " 'save': 320,\n",
       " 'sex': 321,\n",
       " 'age': 322,\n",
       " 'next': 323,\n",
       " 'bring': 324,\n",
       " 'mr': 325,\n",
       " 'case': 326,\n",
       " 'killer': 327,\n",
       " 'heart': 328,\n",
       " 'comment': 329,\n",
       " 'sort': 330,\n",
       " 'creat': 331,\n",
       " 'perhap': 332,\n",
       " 'came': 333,\n",
       " 'brother': 334,\n",
       " 'sever': 335,\n",
       " 'joke': 336,\n",
       " 'art': 337,\n",
       " 'dialogu': 338,\n",
       " 'game': 339,\n",
       " 'small': 340,\n",
       " 'base': 341,\n",
       " 'flick': 342,\n",
       " 'written': 343,\n",
       " 'sequenc': 344,\n",
       " 'meet': 345,\n",
       " 'earli': 346,\n",
       " 'often': 347,\n",
       " 'other': 348,\n",
       " 'mother': 349,\n",
       " 'develop': 350,\n",
       " 'humor': 351,\n",
       " 'actress': 352,\n",
       " 'consid': 353,\n",
       " 'dark': 354,\n",
       " 'guess': 355,\n",
       " 'amaz': 356,\n",
       " 'unfortun': 357,\n",
       " 'lost': 358,\n",
       " 'light': 359,\n",
       " 'exampl': 360,\n",
       " 'cinema': 361,\n",
       " 'drama': 362,\n",
       " 'ye': 363,\n",
       " 'white': 364,\n",
       " 'experi': 365,\n",
       " 'imagin': 366,\n",
       " 'mention': 367,\n",
       " 'stop': 368,\n",
       " 'natur': 369,\n",
       " 'forc': 370,\n",
       " 'manag': 371,\n",
       " 'felt': 372,\n",
       " 'present': 373,\n",
       " 'cut': 374,\n",
       " 'children': 375,\n",
       " 'fail': 376,\n",
       " 'son': 377,\n",
       " 'support': 378,\n",
       " 'qualiti': 379,\n",
       " 'car': 380,\n",
       " 'ask': 381,\n",
       " 'hit': 382,\n",
       " 'side': 383,\n",
       " 'voic': 384,\n",
       " 'extrem': 385,\n",
       " 'impress': 386,\n",
       " 'wors': 387,\n",
       " 'evil': 388,\n",
       " 'stand': 389,\n",
       " 'went': 390,\n",
       " 'certainli': 391,\n",
       " 'basic': 392,\n",
       " 'oh': 393,\n",
       " 'overal': 394,\n",
       " 'favorit': 395,\n",
       " 'horribl': 396,\n",
       " 'mysteri': 397,\n",
       " 'number': 398,\n",
       " 'type': 399,\n",
       " 'danc': 400,\n",
       " 'wait': 401,\n",
       " 'hero': 402,\n",
       " '5': 403,\n",
       " 'alreadi': 404,\n",
       " 'learn': 405,\n",
       " 'matter': 406,\n",
       " '4': 407,\n",
       " 'michael': 408,\n",
       " 'genr': 409,\n",
       " 'fine': 410,\n",
       " 'despit': 411,\n",
       " 'throughout': 412,\n",
       " 'walk': 413,\n",
       " 'success': 414,\n",
       " 'histori': 415,\n",
       " 'question': 416,\n",
       " 'zombi': 417,\n",
       " 'town': 418,\n",
       " 'relationship': 419,\n",
       " 'realiz': 420,\n",
       " 'past': 421,\n",
       " 'child': 422,\n",
       " 'daughter': 423,\n",
       " 'late': 424,\n",
       " 'b': 425,\n",
       " 'wish': 426,\n",
       " 'hate': 427,\n",
       " 'credit': 428,\n",
       " 'event': 429,\n",
       " 'theme': 430,\n",
       " 'touch': 431,\n",
       " 'citi': 432,\n",
       " 'today': 433,\n",
       " 'sometim': 434,\n",
       " 'behind': 435,\n",
       " 'god': 436,\n",
       " 'twist': 437,\n",
       " 'sit': 438,\n",
       " 'deal': 439,\n",
       " 'stay': 440,\n",
       " 'annoy': 441,\n",
       " 'abl': 442,\n",
       " 'rent': 443,\n",
       " 'pleas': 444,\n",
       " 'edit': 445,\n",
       " 'blood': 446,\n",
       " 'deserv': 447,\n",
       " 'anyway': 448,\n",
       " 'comic': 449,\n",
       " 'appar': 450,\n",
       " 'soon': 451,\n",
       " 'gave': 452,\n",
       " 'etc': 453,\n",
       " 'level': 454,\n",
       " 'slow': 455,\n",
       " 'chanc': 456,\n",
       " 'score': 457,\n",
       " 'bodi': 458,\n",
       " 'brilliant': 459,\n",
       " 'incred': 460,\n",
       " 'figur': 461,\n",
       " 'situat': 462,\n",
       " 'major': 463,\n",
       " 'self': 464,\n",
       " 'stuff': 465,\n",
       " 'decent': 466,\n",
       " 'element': 467,\n",
       " 'return': 468,\n",
       " 'dream': 469,\n",
       " 'obvious': 470,\n",
       " 'order': 471,\n",
       " 'continu': 472,\n",
       " 'pace': 473,\n",
       " 'ridicul': 474,\n",
       " 'happi': 475,\n",
       " 'group': 476,\n",
       " 'highli': 477,\n",
       " 'add': 478,\n",
       " 'thank': 479,\n",
       " 'ladi': 480,\n",
       " 'novel': 481,\n",
       " 'pain': 482,\n",
       " 'speak': 483,\n",
       " 'career': 484,\n",
       " 'shoot': 485,\n",
       " 'strang': 486,\n",
       " 'heard': 487,\n",
       " 'sad': 488,\n",
       " 'husband': 489,\n",
       " 'polic': 490,\n",
       " 'import': 491,\n",
       " 'break': 492,\n",
       " 'took': 493,\n",
       " 'cannot': 494,\n",
       " 'strong': 495,\n",
       " 'predict': 496,\n",
       " 'robert': 497,\n",
       " 'violenc': 498,\n",
       " 'hilari': 499,\n",
       " 'recent': 500,\n",
       " 'countri': 501,\n",
       " 'known': 502,\n",
       " 'particularli': 503,\n",
       " 'pick': 504,\n",
       " 'documentari': 505,\n",
       " 'season': 506,\n",
       " 'critic': 507,\n",
       " 'jame': 508,\n",
       " 'compar': 509,\n",
       " 'obviou': 510,\n",
       " 'alon': 511,\n",
       " 'told': 512,\n",
       " 'state': 513,\n",
       " 'rock': 514,\n",
       " 'visual': 515,\n",
       " 'offer': 516,\n",
       " 'theater': 517,\n",
       " 'exist': 518,\n",
       " 'opinion': 519,\n",
       " 'gore': 520,\n",
       " 'crap': 521,\n",
       " 'hold': 522,\n",
       " 'result': 523,\n",
       " 'realiti': 524,\n",
       " 'hear': 525,\n",
       " 'room': 526,\n",
       " 'clich': 527,\n",
       " 'effort': 528,\n",
       " 'thriller': 529,\n",
       " 'caus': 530,\n",
       " 'serious': 531,\n",
       " 'explain': 532,\n",
       " 'sequel': 533,\n",
       " 'king': 534,\n",
       " 'local': 535,\n",
       " 'ago': 536,\n",
       " 'hell': 537,\n",
       " 'none': 538,\n",
       " 'note': 539,\n",
       " 'allow': 540,\n",
       " 'sister': 541,\n",
       " 'david': 542,\n",
       " 'simpl': 543,\n",
       " 'femal': 544,\n",
       " 'deliv': 545,\n",
       " 'ok': 546,\n",
       " 'class': 547,\n",
       " 'convinc': 548,\n",
       " 'check': 549,\n",
       " 'suspens': 550,\n",
       " 'win': 551,\n",
       " 'buy': 552,\n",
       " 'oscar': 553,\n",
       " 'huge': 554,\n",
       " 'valu': 555,\n",
       " 'sexual': 556,\n",
       " 'cool': 557,\n",
       " 'scari': 558,\n",
       " 'excit': 559,\n",
       " 'similar': 560,\n",
       " 'exactli': 561,\n",
       " 'apart': 562,\n",
       " 'provid': 563,\n",
       " 'avoid': 564,\n",
       " 'shown': 565,\n",
       " 'seriou': 566,\n",
       " 'english': 567,\n",
       " 'taken': 568,\n",
       " 'whose': 569,\n",
       " 'cinematographi': 570,\n",
       " 'shock': 571,\n",
       " 'polit': 572,\n",
       " 'spoiler': 573,\n",
       " 'offic': 574,\n",
       " 'across': 575,\n",
       " 'middl': 576,\n",
       " 'pass': 577,\n",
       " 'street': 578,\n",
       " 'messag': 579,\n",
       " 'silli': 580,\n",
       " 'somewhat': 581,\n",
       " 'charm': 582,\n",
       " 'modern': 583,\n",
       " 'confus': 584,\n",
       " 'filmmak': 585,\n",
       " 'form': 586,\n",
       " 'tale': 587,\n",
       " 'singl': 588,\n",
       " 'jack': 589,\n",
       " 'mostli': 590,\n",
       " 'william': 591,\n",
       " 'carri': 592,\n",
       " 'attent': 593,\n",
       " 'sing': 594,\n",
       " 'subject': 595,\n",
       " 'five': 596,\n",
       " 'richard': 597,\n",
       " 'prove': 598,\n",
       " 'stage': 599,\n",
       " 'team': 600,\n",
       " 'cop': 601,\n",
       " 'unlik': 602,\n",
       " 'georg': 603,\n",
       " 'televis': 604,\n",
       " 'monster': 605,\n",
       " 'earth': 606,\n",
       " 'cover': 607,\n",
       " 'villain': 608,\n",
       " 'pay': 609,\n",
       " 'marri': 610,\n",
       " 'toward': 611,\n",
       " 'build': 612,\n",
       " 'parent': 613,\n",
       " 'pull': 614,\n",
       " 'due': 615,\n",
       " 'fill': 616,\n",
       " 'respect': 617,\n",
       " 'dialog': 618,\n",
       " 'four': 619,\n",
       " 'remind': 620,\n",
       " 'futur': 621,\n",
       " 'weak': 622,\n",
       " 'typic': 623,\n",
       " '7': 624,\n",
       " 'cheap': 625,\n",
       " 'intellig': 626,\n",
       " 'atmospher': 627,\n",
       " 'british': 628,\n",
       " '80': 629,\n",
       " 'clearli': 630,\n",
       " 'paul': 631,\n",
       " 'non': 632,\n",
       " 'dog': 633,\n",
       " 'fast': 634,\n",
       " 'knew': 635,\n",
       " 'artist': 636,\n",
       " '8': 637,\n",
       " 'crime': 638,\n",
       " 'easili': 639,\n",
       " 'escap': 640,\n",
       " 'doubt': 641,\n",
       " 'adult': 642,\n",
       " 'detail': 643,\n",
       " 'date': 644,\n",
       " 'member': 645,\n",
       " 'romant': 646,\n",
       " 'fire': 647,\n",
       " 'gun': 648,\n",
       " 'drive': 649,\n",
       " 'straight': 650,\n",
       " 'beyond': 651,\n",
       " 'fit': 652,\n",
       " 'attack': 653,\n",
       " 'imag': 654,\n",
       " 'upon': 655,\n",
       " 'posit': 656,\n",
       " 'whether': 657,\n",
       " 'peter': 658,\n",
       " 'fantast': 659,\n",
       " 'captur': 660,\n",
       " 'aspect': 661,\n",
       " 'appreci': 662,\n",
       " 'ten': 663,\n",
       " 'plan': 664,\n",
       " 'discov': 665,\n",
       " 'remain': 666,\n",
       " 'period': 667,\n",
       " 'near': 668,\n",
       " 'realist': 669,\n",
       " 'air': 670,\n",
       " 'mark': 671,\n",
       " 'red': 672,\n",
       " 'dull': 673,\n",
       " 'adapt': 674,\n",
       " 'within': 675,\n",
       " 'spend': 676,\n",
       " 'lose': 677,\n",
       " 'color': 678,\n",
       " 'materi': 679,\n",
       " 'chase': 680,\n",
       " 'mari': 681,\n",
       " 'storylin': 682,\n",
       " 'forget': 683,\n",
       " 'bunch': 684,\n",
       " 'clear': 685,\n",
       " 'lee': 686,\n",
       " 'victim': 687,\n",
       " 'nearli': 688,\n",
       " 'box': 689,\n",
       " 'york': 690,\n",
       " 'inspir': 691,\n",
       " 'match': 692,\n",
       " 'mess': 693,\n",
       " 'finish': 694,\n",
       " 'standard': 695,\n",
       " 'easi': 696,\n",
       " 'truth': 697,\n",
       " 'suffer': 698,\n",
       " 'busi': 699,\n",
       " 'space': 700,\n",
       " 'dramat': 701,\n",
       " 'bill': 702,\n",
       " 'western': 703,\n",
       " 'e': 704,\n",
       " 'list': 705,\n",
       " 'battl': 706,\n",
       " 'notic': 707,\n",
       " 'de': 708,\n",
       " 'french': 709,\n",
       " 'ad': 710,\n",
       " '9': 711,\n",
       " 'tom': 712,\n",
       " 'larg': 713,\n",
       " 'among': 714,\n",
       " 'eventu': 715,\n",
       " 'accept': 716,\n",
       " 'train': 717,\n",
       " 'agre': 718,\n",
       " 'soundtrack': 719,\n",
       " 'spirit': 720,\n",
       " 'third': 721,\n",
       " 'teenag': 722,\n",
       " 'adventur': 723,\n",
       " 'soldier': 724,\n",
       " 'drug': 725,\n",
       " 'famou': 726,\n",
       " 'suggest': 727,\n",
       " 'sorri': 728,\n",
       " 'normal': 729,\n",
       " 'cri': 730,\n",
       " 'babi': 731,\n",
       " 'troubl': 732,\n",
       " 'ultim': 733,\n",
       " 'contain': 734,\n",
       " 'certain': 735,\n",
       " 'cultur': 736,\n",
       " 'romanc': 737,\n",
       " 'rare': 738,\n",
       " 'lame': 739,\n",
       " 'somehow': 740,\n",
       " 'mix': 741,\n",
       " 'disney': 742,\n",
       " 'gone': 743,\n",
       " 'cartoon': 744,\n",
       " 'student': 745,\n",
       " 'fear': 746,\n",
       " 'reveal': 747,\n",
       " 'kept': 748,\n",
       " 'suck': 749,\n",
       " 'attract': 750,\n",
       " 'appeal': 751,\n",
       " 'premis': 752,\n",
       " 'design': 753,\n",
       " 'secret': 754,\n",
       " 'greatest': 755,\n",
       " 'shame': 756,\n",
       " 'throw': 757,\n",
       " 'scare': 758,\n",
       " 'copi': 759,\n",
       " 'wit': 760,\n",
       " 'admit': 761,\n",
       " 'america': 762,\n",
       " 'relat': 763,\n",
       " 'brought': 764,\n",
       " 'particular': 765,\n",
       " 'screenplay': 766,\n",
       " 'whatev': 767,\n",
       " 'pure': 768,\n",
       " '70': 769,\n",
       " 'averag': 770,\n",
       " 'harri': 771,\n",
       " 'master': 772,\n",
       " 'describ': 773,\n",
       " 'male': 774,\n",
       " 'treat': 775,\n",
       " '20': 776,\n",
       " 'issu': 777,\n",
       " 'fantasi': 778,\n",
       " 'warn': 779,\n",
       " 'inde': 780,\n",
       " 'background': 781,\n",
       " 'forward': 782,\n",
       " 'project': 783,\n",
       " 'free': 784,\n",
       " 'memor': 785,\n",
       " 'japanes': 786,\n",
       " 'poorli': 787,\n",
       " 'award': 788,\n",
       " 'locat': 789,\n",
       " 'amus': 790,\n",
       " 'potenti': 791,\n",
       " 'struggl': 792,\n",
       " 'weird': 793,\n",
       " 'magic': 794,\n",
       " 'societi': 795,\n",
       " 'okay': 796,\n",
       " 'doctor': 797,\n",
       " 'imdb': 798,\n",
       " 'accent': 799,\n",
       " 'hot': 800,\n",
       " 'water': 801,\n",
       " '30': 802,\n",
       " 'dr': 803,\n",
       " 'alien': 804,\n",
       " 'express': 805,\n",
       " 'odd': 806,\n",
       " 'choic': 807,\n",
       " 'crazi': 808,\n",
       " 'fiction': 809,\n",
       " 'studio': 810,\n",
       " 'control': 811,\n",
       " 'becam': 812,\n",
       " 'masterpiec': 813,\n",
       " 'fli': 814,\n",
       " 'difficult': 815,\n",
       " 'joe': 816,\n",
       " 'scream': 817,\n",
       " 'costum': 818,\n",
       " 'lover': 819,\n",
       " 'uniqu': 820,\n",
       " 'refer': 821,\n",
       " 'remak': 822,\n",
       " 'girlfriend': 823,\n",
       " 'vampir': 824,\n",
       " 'prison': 825,\n",
       " 'execut': 826,\n",
       " 'wear': 827,\n",
       " 'jump': 828,\n",
       " 'unless': 829,\n",
       " 'wood': 830,\n",
       " 'creepi': 831,\n",
       " 'cheesi': 832,\n",
       " 'superb': 833,\n",
       " 'otherwis': 834,\n",
       " 'parti': 835,\n",
       " 'roll': 836,\n",
       " 'ghost': 837,\n",
       " 'public': 838,\n",
       " 'mad': 839,\n",
       " 'depict': 840,\n",
       " 'jane': 841,\n",
       " 'badli': 842,\n",
       " 'moral': 843,\n",
       " 'earlier': 844,\n",
       " 'week': 845,\n",
       " 'fi': 846,\n",
       " 'dumb': 847,\n",
       " 'grow': 848,\n",
       " 'flaw': 849,\n",
       " 'deep': 850,\n",
       " 'sci': 851,\n",
       " 'maker': 852,\n",
       " 'cat': 853,\n",
       " 'older': 854,\n",
       " 'connect': 855,\n",
       " 'footag': 856,\n",
       " 'bother': 857,\n",
       " 'plenti': 858,\n",
       " 'outsid': 859,\n",
       " 'stick': 860,\n",
       " 'gay': 861,\n",
       " 'catch': 862,\n",
       " 'co': 863,\n",
       " 'plu': 864,\n",
       " 'popular': 865,\n",
       " 'equal': 866,\n",
       " 'social': 867,\n",
       " 'disturb': 868,\n",
       " 'quickli': 869,\n",
       " 'perfectli': 870,\n",
       " 'dress': 871,\n",
       " '90': 872,\n",
       " 'era': 873,\n",
       " 'mistak': 874,\n",
       " 'lie': 875,\n",
       " 'ride': 876,\n",
       " 'previou': 877,\n",
       " 'combin': 878,\n",
       " 'band': 879,\n",
       " 'concept': 880,\n",
       " 'rich': 881,\n",
       " 'surviv': 882,\n",
       " 'answer': 883,\n",
       " 'front': 884,\n",
       " 'christma': 885,\n",
       " 'sweet': 886,\n",
       " 'insid': 887,\n",
       " 'concern': 888,\n",
       " 'eat': 889,\n",
       " 'bare': 890,\n",
       " 'listen': 891,\n",
       " 'beat': 892,\n",
       " 'ben': 893,\n",
       " 'c': 894,\n",
       " 'term': 895,\n",
       " 'serv': 896,\n",
       " 'la': 897,\n",
       " 'german': 898,\n",
       " 'meant': 899,\n",
       " 'hardli': 900,\n",
       " 'stereotyp': 901,\n",
       " 'innoc': 902,\n",
       " 'law': 903,\n",
       " 'desper': 904,\n",
       " 'promis': 905,\n",
       " 'memori': 906,\n",
       " 'intent': 907,\n",
       " 'cute': 908,\n",
       " 'variou': 909,\n",
       " 'steal': 910,\n",
       " 'inform': 911,\n",
       " 'brain': 912,\n",
       " 'post': 913,\n",
       " 'tone': 914,\n",
       " 'island': 915,\n",
       " 'amount': 916,\n",
       " 'compani': 917,\n",
       " 'track': 918,\n",
       " 'nuditi': 919,\n",
       " 'store': 920,\n",
       " 'claim': 921,\n",
       " '50': 922,\n",
       " 'flat': 923,\n",
       " 'hair': 924,\n",
       " 'univers': 925,\n",
       " 'land': 926,\n",
       " 'kick': 927,\n",
       " 'fairli': 928,\n",
       " 'danger': 929,\n",
       " 'scott': 930,\n",
       " 'player': 931,\n",
       " 'plain': 932,\n",
       " 'crew': 933,\n",
       " 'step': 934,\n",
       " 'toni': 935,\n",
       " 'share': 936,\n",
       " 'centuri': 937,\n",
       " 'tast': 938,\n",
       " 'engag': 939,\n",
       " 'achiev': 940,\n",
       " 'travel': 941,\n",
       " 'cold': 942,\n",
       " 'suit': 943,\n",
       " 'rip': 944,\n",
       " 'record': 945,\n",
       " 'manner': 946,\n",
       " 'sadli': 947,\n",
       " 'tension': 948,\n",
       " 'wrote': 949,\n",
       " 'spot': 950,\n",
       " 'intens': 951,\n",
       " 'fascin': 952,\n",
       " 'familiar': 953,\n",
       " 'depth': 954,\n",
       " 'remark': 955,\n",
       " 'burn': 956,\n",
       " 'histor': 957,\n",
       " 'destroy': 958,\n",
       " 'sleep': 959,\n",
       " 'purpos': 960,\n",
       " 'languag': 961,\n",
       " 'ruin': 962,\n",
       " 'ignor': 963,\n",
       " 'delight': 964,\n",
       " 'unbeliev': 965,\n",
       " 'italian': 966,\n",
       " 'collect': 967,\n",
       " 'abil': 968,\n",
       " 'soul': 969,\n",
       " 'clever': 970,\n",
       " 'detect': 971,\n",
       " 'violent': 972,\n",
       " 'rape': 973,\n",
       " 'reach': 974,\n",
       " 'door': 975,\n",
       " 'scienc': 976,\n",
       " 'trash': 977,\n",
       " 'liter': 978,\n",
       " 'commun': 979,\n",
       " 'reveng': 980,\n",
       " 'caught': 981,\n",
       " 'creatur': 982,\n",
       " 'trip': 983,\n",
       " 'approach': 984,\n",
       " 'fashion': 985,\n",
       " 'intrigu': 986,\n",
       " 'introduc': 987,\n",
       " 'skill': 988,\n",
       " 'paint': 989,\n",
       " 'channel': 990,\n",
       " 'complex': 991,\n",
       " 'camp': 992,\n",
       " 'christian': 993,\n",
       " 'hole': 994,\n",
       " 'extra': 995,\n",
       " 'immedi': 996,\n",
       " 'mental': 997,\n",
       " 'limit': 998,\n",
       " 'ann': 999,\n",
       " 'comput': 1000,\n",
       " 'million': 1001,\n",
       " ...}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(word_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/pytorch' # The folder we will use for storing data\n",
    "if not os.path.exists(data_dir): # Make sure that the folder exists\n",
    "    os.makedirs(data_dir)\n",
    "with open(os.path.join(data_dir, 'word_dict.pkl'), \"wb\") as f:\n",
    "    pickle.dump(word_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_pad(word_dict, sentence, pad=500):\n",
    "    NOWORD = 0 # We will use 0 to represent the 'no word' category\n",
    "    INFREQ = 1 # and we use 1 to represent the infrequent words, i.e., words not appearing in word_dict\n",
    "    \n",
    "    working_sentence = [NOWORD] * pad\n",
    "    \n",
    "    for word_index, word in enumerate(sentence[:pad]):\n",
    "        if word in word_dict:\n",
    "            working_sentence[word_index] = word_dict[word]\n",
    "        else:\n",
    "            working_sentence[word_index] = INFREQ\n",
    "            \n",
    "    return working_sentence, min(len(sentence), pad)\n",
    "\n",
    "def convert_and_pad_data(word_dict, data, pad=500):\n",
    "    result = []\n",
    "    lengths = []\n",
    "    \n",
    "    for sentence in data:\n",
    "        converted, leng = convert_and_pad(word_dict, sentence, pad)\n",
    "        result.append(converted)\n",
    "        lengths.append(leng)\n",
    "        \n",
    "    return np.array(result), np.array(lengths)\n",
    "\n",
    "train_X, train_X_len = convert_and_pad_data(word_dict, train_X)\n",
    "test_X, test_X_len = convert_and_pad_data(word_dict, test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X  = np.array(pd.concat([pd.DataFrame(train_X_len), pd.DataFrame(train_X)], axis=1).values)\n",
    "X2 = np.array(pd.concat([pd.DataFrame(test_X_len), pd.DataFrame(test_X)], axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize train/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "# Read in only the first 250 rows\n",
    "# train_sample = pd.read_csv(os.path.join(data_dir, 'train.csv'), header=None, names=None, nrows=250)\n",
    "\n",
    "# Turn the input pandas dataframe into tensors\n",
    "train_sample_y = torch.from_numpy(np.array(train_y)[:] ).float().squeeze()\n",
    "train_sample_X = torch.from_numpy(X[:] ).long()\n",
    "\n",
    "test_sample_y = torch.from_numpy(np.array(test_y)[:] ).float().squeeze()\n",
    "test_sample_X = torch.from_numpy(X2[:] ).long()\n",
    "\n",
    "# Build the dataset\n",
    "val_split = 15000\n",
    "class_balance = val_split//2\n",
    "\n",
    "pos_idx = np.where(test_sample_y.numpy().astype(int) == 1)[0]\n",
    "neg_idx = np.where(test_sample_y.numpy().astype(int) == 0)[0]\n",
    "\n",
    "\n",
    "val_idx  = np.concatenate((pos_idx[-class_balance:],neg_idx[-class_balance:]))\n",
    "test_idx = np.concatenate((pos_idx[:-class_balance],neg_idx[:-class_balance]))\n",
    "\n",
    "\n",
    "train_sample_ds = torch.utils.data.TensorDataset(train_sample_X, train_sample_y)\n",
    "train_sample_dl = torch.utils.data.DataLoader(train_sample_ds,shuffle= True, batch_size=32)\n",
    "\n",
    "val_sample_ds = torch.utils.data.TensorDataset(test_sample_X[val_idx], test_sample_y[val_idx])\n",
    "val_sample_dl = torch.utils.data.DataLoader(val_sample_ds,shuffle = True, batch_size=32)\n",
    "\n",
    "test_sample_ds = torch.utils.data.TensorDataset(test_sample_X[test_idx], test_sample_y[test_idx])\n",
    "test_sample_dl = torch.utils.data.DataLoader(test_sample_ds,shuffle = True, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the simple RNN model we will be using to perform Sentiment Analysis.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, hidden_dim,layers, vocab_size):\n",
    "        \"\"\"\n",
    "        Initialize the model by settingg up the various layers.\n",
    "        \"\"\"\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        \n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "             \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, layers , dropout = 0.5)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.dense = nn.Linear(in_features=hidden_dim, out_features=1)\n",
    "#         self.dense_p = nn.Linear(in_features=hidden_dim, out_features=100)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "        self.word_dict = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input.\n",
    "        \"\"\"\n",
    "        x = x.t()\n",
    "        lengths = x[0,:]\n",
    "        reviews = x[1:,:]\n",
    "        embeds = self.embedding(reviews)\n",
    "\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        out = self.dense(lstm_out)\n",
    "        out = out[lengths - 1, range(len(lengths))]\n",
    "\n",
    "        return self.sig(out.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train(model, train_loader,val_loader, epochs, optimizer, loss_fn, device):\n",
    "    losses = []\n",
    "    accuracy = []\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_accuracy = 0\n",
    "        total_val_loss = 0\n",
    "        total_val_accuracy = 0\n",
    "        \n",
    "        sanity_acc = 0\n",
    "        for batch in train_loader:         \n",
    "            batch_X, batch_y = batch\n",
    "            \n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            # TODO: Complete this train method to train the model provided.\n",
    "            sentiments = model(batch_X)\n",
    "            loss = loss_fn(sentiments , batch_y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "#             nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            optimizer.step()\n",
    "    \n",
    "            total_accuracy += f1_score(np.round(sentiments.data.cpu().numpy()).astype(np.int) ,  batch_y.data.cpu().numpy().astype(np.int) ,average = 'macro')\n",
    "        \n",
    "            cm = confusion_matrix(np.round(sentiments.data.cpu().numpy()).astype(np.int), batch_y.data.cpu().numpy().astype(np.int) )\n",
    "#             print(cm,cm[0,0],cm[1,1],sum(cm.ravel()))\n",
    "            sanity_acc += (cm[0,0]+cm[1,1])/sum(cm.ravel())\n",
    "            \n",
    "            \n",
    "            total_loss += loss.data.item()\n",
    "    \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:         \n",
    "                batch_X, batch_y = batch\n",
    "\n",
    "                batch_X = batch_X.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "\n",
    "                # TODO: Complete this train method to train the model provided.\n",
    "                sentiments = model(batch_X)\n",
    "                loss = loss_fn(sentiments , batch_y)\n",
    "\n",
    "                total_val_accuracy += f1_score( np.round(sentiments.data.cpu().numpy()).astype(np.int) , batch_y.data.cpu().numpy().astype(np.int) ,average = 'macro')\n",
    "                total_val_loss += loss.data.item()\n",
    "        \n",
    "        print( f\"Epoch: {epoch} train : Loss: {  round(total_loss / len(train_loader) ,5) } Accuracy:{ total_accuracy / len(train_loader)} sanity:{sanity_acc/len(train_loader)}    val : Loss: { round(total_val_loss / len(val_loader),5)} Accuracy:{ total_val_accuracy / len(val_loader)} \")\n",
    "        \n",
    "        losses.append([round(total_loss / len(train_loader) ,5),round(total_val_loss / len(val_loader),5)])\n",
    "        accuracy.append([total_accuracy / len(train_loader),total_val_accuracy / len(val_loader)])\n",
    "    return np.array(losses),np.array(accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-c6d3606c7877>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# device = torch.device('cpu')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "# from train.model import LSTMClassifier\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "model = LSTMClassifier(300, 100,3, 5000).to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr= 0.001)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "losses,accuracy = train(model, train_sample_dl, 4, optimizer, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,(ax1,ax2) = plt.subplots(2,1)\n",
    "# losses ,accuracy = np.array(losses),np.array(accuracy)\n",
    "ax1.plot(losses[:,0],label = 'train')\n",
    "ax1.plot(losses[:,1],label = 'val')\n",
    "ax1.legend()\n",
    "ax2.plot(accuracy[:,0],label = 'train')\n",
    "ax2.plot(accuracy[:,1],label = 'val')\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.33317 Accuracy:0.859363529805209\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "total_accuracy = 0\n",
    "for batch in test_sample_dl:         \n",
    "    batch_X, batch_y = batch\n",
    "\n",
    "    batch_X = batch_X.to(device)\n",
    "    batch_y = batch_y.to(device)\n",
    "\n",
    "    # TODO: Complete this train method to train the model provided.\n",
    "    sentiments = model(batch_X)\n",
    "    loss = loss_fn(sentiments , batch_y)\n",
    "\n",
    "    total_accuracy += f1_score( np.round(sentiments.data.cpu().numpy()).astype(np.int) , batch_y.data.cpu().numpy().astype(np.int) ,average = 'macro')\n",
    "    total_loss += loss.data.item()\n",
    "\n",
    "print( f\"Loss: {  round(total_loss / len(test_sample_dl) ,5) } Accuracy:{ total_accuracy / len(test_sample_dl)}\" ) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
